

>>> from pyspark.sql.types import *
>>> from pyspark.sql.functions import *
>>> from pyspark.sql.session import SparkSession
>>> from pyspark.sql import SQLContext
>>> sqlContext = SQLContext(sc)
>>> from pyspark.ml import Pipeline

>>> from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler
>>> from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit

>>> from pyspark.ml.regression import DecisionTreeRegressor
>>> from pyspark.ml.regression import GBTRegressor
>>> from pyspark.ml.evaluation import RegressionEvaluator
>>> from pyspark.ml.feature import OneHotEncoder
>>> from pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator
>>> from pyspark.ml.classification import LogisticRegression

>>> from pyspark.sql import functions as F
>>> import pyspark.sql.functions as F
>>> import sys

>>> csv = spark.read.csv('/user/skundu/iowaliquorsales_sample.csv', inferSchema=True, header=True)

>>> csv.show(3)

>>> csv.registerTempTable("temp")

>>> csv1 = sqlContext.sql("""select Pack, `Bottle Volume (ml)` as BottleVolumeInMl, `State Bottle Cost` as StateBottleCost, `State Bottle Retail` as StateBottleRetail, `Bottles Sold` as BottlesSold, `Sale (Dollars)` as SaleInDollars, `Volume Sold (Liters)` as VolumeSoldInLitres from temp""")

>>> df1 = csv1.filter(csv1.StateBottleCost.isNotNull())
>>> df2 = df1.filter(df1.StateBottleRetail.isNotNull())
>>> df3 = df2.filter(df2.BottleVolumeInMl.isNotNull())
>>> df4 = df3.filter(df3.Pack.isNotNull())
>>> df5 = df4.filter(df4.BottlesSold.isNotNull())
>>> df6 = df5.filter(df5.SaleInDollars.isNotNull())
>>> df7 = df6.filter(df6.VolumeSoldInLitres.isNotNull())

>>> data = df7.select(col("Pack").cast(DoubleType()), col("BottleVolumeInMl").cast(DoubleType()), "StateBottleCost", "StateBottleRetail", col("BottlesSold").cast(DoubleType()), "VolumeSoldInLitres
", col("SaleInDollars").alias("label"))

>>> data.show(5)

>>> splits = data.randomSplit([0.7, 0.3])
>>> gbt_train = splits[0]
>>> gbt_test = splits[1].withColumnRenamed("label", "trueLabel")

>>> print ("GBT Training Rows:", gbt_train.count(), "GBT Testing Rows:", gbt_test.count())

>>> gbt_train.show(20)

>>> assembler = VectorAssembler(inputCols = ["Pack", "BottleVolumeInMl","StateBottleCost", "StateBottleRetail", "BottlesSold", "VolumeSoldInLitres"], outputCol="features")

>>> gbt = GBTRegressor(featuresCol='features', labelCol='label', maxBins=77582,  maxIter=2)

>>> gbt_pipeline = Pipeline(stages=[assembler, gbt])

>>> paramGrid_Gbt = (ParamGridBuilder()
              .addGrid(gbt.maxDepth,[2,3])
              .addGrid(gbt.minInfoGain,[0.0, 0.1, 0.2, 0.3])
              .addGrid(gbt.stepSize,[0.05, 0.1, 0.2, 0.4])
              .build())

>>> gbt_tvs = TrainValidationSplit(estimator=gbt_pipeline, evaluator=RegressionEvaluator(), estimatorParamMaps=paramGrid_Gbt, trainRatio=0.8)

>>> gbt_model = gbt_tvs.fit(gbt_train)

>>> gbt_prediction = gbt_model.transform(gbt_test)

>>> gbt_predicted = gbt_prediction.select("features", "prediction", "trueLabel")

>>> gbt_predicted.show(20)

>>> gbt_evaluator = RegressionEvaluator(labelCol="trueLabel", predictionCol="prediction", metricName="rmse")

>>> gbt_rmse = gbt_evaluator.evaluate(gbt_prediction)

>>> print ("Root Mean Square Error (RMSE_GBT):", gbt_rmse)

