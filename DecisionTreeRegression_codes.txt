>>> from pyspark.sql.types import *
>>> from pyspark.sql.functions import *
>>> from pyspark.sql.session import SparkSession
>>> from pyspark.sql import SQLContext
>>> sqlContext = SQLContext(sc)
>>> from pyspark.ml import Pipeline

>>> from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler
>>> from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit

>>> from pyspark.ml.regression import DecisionTreeRegressor
>>> from pyspark.ml.regression import GBTRegressor
>>> from pyspark.ml.evaluation import RegressionEvaluator
>>> from pyspark.ml.feature import OneHotEncoder
>>> from pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator
>>> from pyspark.ml.classification import LogisticRegression

>>> from pyspark.sql import functions as F
>>> import pyspark.sql.functions as F
>>> import sys

>>> csv = spark.read.csv('/user/skundu/iowa_Liquor_Sales.csv', inferSchema=True, header=True)

>>> csv.show(3)


>>> csv.registerTempTable("temp")


>>> csv1 = sqlContext.sql("""select Pack, `Bottle Volume (ml)` as BottleVolumeInMl, `State Bottle Cost` as StateBottleCost, `State Bottle Retail` as StateBottleRetail, `Bottles Sold` as BottlesSold, `Sale (Dollars)` as SaleInDollars, `Volume Sold (Liters)` as VolumeSoldInLitres from temp""")


>>> df1 = csv1.filter(csv1.StateBottleCost.isNotNull())

>>> df2 = df1.filter(df1.StateBottleRetail.isNotNull())

>>> df3 = df2.filter(df2.BottleVolumeInMl.isNotNull())

>>> df4 = df3.filter(df3.Pack.isNotNull())

>>> df5 = df4.filter(df4.BottlesSold.isNotNull())

>>> df6 = df5.filter(df5.SaleInDollars.isNotNull())

>>> df7 = df6.filter(df6.VolumeSoldInLitres.isNotNull())


>>> data = df7.select(col("Pack").cast(DoubleType()), col("BottleVolumeInMl").cast(DoubleType()), "StateBottleCost", "StateBottleRetail", col("BottlesSold").cast(DoubleType()), "VolumeSoldInLitres", col("SaleInDollars").alias("label"))

>>> data.show(5)




>>> splits = data.randomSplit([0.7, 0.3])

>>> dtr_train = splits[0]

>>> dtr_test = splits[1].withColumnRenamed("label", "trueLabel")


>>> print ("DTR Training Rows:", dtr_train.count(), "DTR Testing Rows:", dtr_test.count())




>>> dtr_train.show(20)




>>> assembler = VectorAssembler(inputCols = ["Pack", "BottleVolumeInMl","StateBottleCost", "StateBottleRetail", "BottlesSold", "VolumeSoldInLitres"], outputCol="features")

>>> dtr = DecisionTreeRegressor(featuresCol='features', labelCol='label', maxBins=77582)

>>> dtr_pipeline = Pipeline(stages=[assembler, dtr])

>>> paramGridDtr = ParamGridBuilder().build()

>>> cvDtr = CrossValidator(estimator=dtr_pipeline, evaluator=RegressionEvaluator(), estimatorParamMaps=paramGridDtr, numFolds=5)

>>> dtr_model = cvDtr.fit(dtr_train)

>>> dtr_prediction = dtr_model.transform(dtr_test)

>>> dtr_predicted = dtr_prediction.select("features", "prediction", "trueLabel")

>>> dtr_predicted.show(20)



>>> dtr_evaluator = RegressionEvaluator(labelCol="trueLabel", predictionCol="prediction", metricName="rmse")

>>> dtr_rmse = dtr_evaluator.evaluate(dtr_prediction)

>>> print ("Root Mean Square Error (RMSE_DTR):", dtr_rmse)

